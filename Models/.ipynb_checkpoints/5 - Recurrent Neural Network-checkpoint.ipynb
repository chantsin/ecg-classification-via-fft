{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baa4424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from tensorflow.keras.layers import Dense, Dropout, GRU, BatchNormalization\n",
    "import load_functions as f\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from Notebooks import ecg_cleaning as c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4624a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Path\n",
    "path = '../data/physionet.org/files/ptb-xl/1.0.3/'\n",
    "metadata = pd.read_csv('../data/cleaned_metadata.csv')\n",
    "\n",
    "# Import data\n",
    "full_data = f.load_signal(path, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d8c800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data shape\n",
    "full_data[0].shape, full_data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7113b6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only looking at Lead II\n",
    "\n",
    "X = full_data[0][:,:,1]\n",
    "\n",
    "y = full_data[1]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fccd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate LabelEncoder\n",
    "label = LabelEncoder()\n",
    "\n",
    "# Fit target column\n",
    "label.fit(y_sample)\n",
    "\n",
    "# Transform target column \n",
    "y_sample = label.transform(y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb4b7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low sampling frequency\n",
    "sig_len = 1000\n",
    "sampling_frequency = 100\n",
    "time = np.arange(0, sig_len) / sampling_frequency\n",
    "\n",
    "# Baseline and PLI removal\n",
    "\n",
    "signal_bl = pd.DataFrame(X).apply(lambda x: c.baseline_removal(x, freq_start=0.1, freq_stop=1.5))\n",
    "signal_pli = pd.DataFrame(signal_bl).apply(lambda x: c.high_freq_removal(x, freq_start=45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7013a1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(signal_pli, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6240d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = keras.Sequential([\n",
    "    # the intermediate recurrent layers should return full sequences\n",
    "    GRU(16, activation='relu', return_sequences=True),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.15),\n",
    "\n",
    "    # the last recurrent layer only returns the final output\n",
    "    GRU(16, activation='relu', return_sequences=False),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.15),\n",
    "\n",
    "    # output layer\n",
    "    Dense(16, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.15),\n",
    "    Dense(10, activation='softmax')],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d94074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile our model with an optimizer, loss function and metric to look at\n",
    "rnn_model.compile(\n",
    "    # Optimizer\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.01),  # learning rate can be adjusted here\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # Metric used to evaluate model\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd24fd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40c7588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_seq = X_train.values.reshape(-1, 1000, 1).astype(\"float\")\n",
    "\n",
    "X_train_seq = X_train.values.reshape(-1, 1000, 1).astype(\"float\")\n",
    "X_test_seq = X_test.values.reshape(-1, 1000, 1).astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcd6af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit our model, adding a validation set as well \n",
    "history = rnn_model.fit(X_train_seq, \n",
    "                    y_train, \n",
    "                    batch_size=32,\n",
    "                    epochs=30, \n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                             patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a70683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data and generate predictions\n",
    "train_accuracy = history.history[\"sparse_categorical_accuracy\"][-1]\n",
    "result = rnn_model.evaluate(np.real(X_test_seq, y_test, verbose=0)\n",
    "#result = rnn_model.evaluate(np.real(X_test.values.reshape(-1, 1000, 1)), y_test, verbose=0)\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {result[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783026ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting loss function \n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e3991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the predicted labels for each test image.\n",
    "predict_probas = rnn_model.predict(X_test_seq)\n",
    "y_predict = np.argmax(predict_probas, axis=1)\n",
    "\n",
    "# Create the confusion matrix using sklearn \n",
    "conf_mat = confusion_matrix(y_test, y_predict)\n",
    "\n",
    "# Since we have many images, it is helpful to show our \n",
    "# results as fractions of the total number of images \n",
    "# for each class.\n",
    "#normalized_conf_mat = conf_mat / conf_mat.sum(axis=1)\n",
    "\n",
    "plt.figure(figsize = (9,7))\n",
    "sns.heatmap(conf_mat,\n",
    "            annot=True,\n",
    "            cbar=False,\n",
    "            cmap=\"rocket_r\",\n",
    "            linewidths=1\n",
    "           )\n",
    "plt.title('Confusion Matrix',size = 25,y=1.01)\n",
    "plt.xlabel(\"Predicted Label\", size = 20)\n",
    "plt.ylabel(\"True Label\", size = 20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
